{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b0fd2a7",
   "metadata": {},
   "source": [
    "## Midterm Project - Sakila Rentals\n",
    "\n",
    "### Prerequisites:\n",
    "\n",
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b95ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import pymongo\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c629e4",
   "metadata": {},
   "source": [
    "#### Declare and assign connection variables for the MongoDB server, the MySQL server, and databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28890801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local Connection String: mongodb://localhost:27017/\n",
      "Atlas Connection String: mongodb+srv://m001-student:m001-mongodb-basics@sandbox.zibbf.mongodb.net\n"
     ]
    }
   ],
   "source": [
    "mysql_host = \"localhost\"\n",
    "mysql_uid = \"root\"\n",
    "mysql_pwd = \"Passw0rd123\"\n",
    "\n",
    "# change to own atlas\n",
    "atlas_cluster = \"sandbox.zibbf\"\n",
    "atlas_uid = \"m001-student\"\n",
    "atlas_pwd = \"m001-mongodb-basics\"\n",
    "\n",
    "mongo_conn_str = {\"local\" : f\"mongodb://localhost:27017/\",\n",
    "    \"atlas\" : f\"mongodb+srv://{atlas_uid}:{atlas_pwd}@{atlas_cluster}.mongodb.net\"\n",
    "}\n",
    "\n",
    "sql_conn_str = f\"mysql+pymysql://{mysql_uid}:{mysql_pwd}@{mysql_host}\"\n",
    "\n",
    "src_dbname = \"sakila\"\n",
    "dst_dbname = \"sakila_dw\"\n",
    "\n",
    "print(f\"Local Connection String: {mongo_conn_str['local']}\")\n",
    "print(f\"Atlas Connection String: {mongo_conn_str['atlas']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928a06",
   "metadata": {},
   "source": [
    "#### Define functions for getting data from and setting data into databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eabb5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sql_dataframe(conn_str, db_name, sql_query):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    \n",
    "    '''Invoke the pd.read_sql() function to query the database, and fill a Pandas DataFrame.'''\n",
    "    conn = sqlEngine.connect()\n",
    "    dframe = pd.read_sql(sql_query, conn);\n",
    "    conn.close()\n",
    "    \n",
    "    return dframe\n",
    "\n",
    "\n",
    "def get_mongo_dataframe(conn_str, db_name, collection, query):\n",
    "    '''Create a connection to MongoDB'''\n",
    "    client = pymongo.MongoClient(conn_str)\n",
    "    \n",
    "    '''Query MongoDB, and fill a python list with documents to create a DataFrame'''\n",
    "    db = client[db_name]\n",
    "    dframe = pd.DataFrame(list(db[collection].find(query)))\n",
    "    dframe.drop(['_id'], axis=1, inplace=True)\n",
    "    client.close()\n",
    "    return dframe\n",
    "\n",
    "\n",
    "def set_dataframe(conn_str, db_name, df, table_name, pk_column, db_operation):\n",
    "    '''Create a connection to the MySQL database'''\n",
    "    sqlEngine = create_engine(conn_str, pool_recycle=3600)\n",
    "    connection = sqlEngine.connect()\n",
    "    \n",
    "    '''Invoke the Pandas DataFrame .to_sql( ) function to either create, or append to, a table'''\n",
    "    if db_operation == \"insert\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='replace')\n",
    "        sqlEngine.execute(f\"ALTER TABLE {table_name} ADD PRIMARY KEY ({pk_column});\")\n",
    "            \n",
    "    elif db_operation == \"update\":\n",
    "        df.to_sql(table_name, con=connection, index=False, if_exists='append')\n",
    "    \n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a3a43",
   "metadata": {},
   "source": [
    "### MySQL:\n",
    "\n",
    "#### ETL directly from source database into destination database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63076365-4542-4cd0-945e-56057a1bb963",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlEngine = create_engine(sql_conn_str, pool_recycle=3600)\n",
    "\n",
    "sqlEngine.execute(f\"DROP DATABASE IF EXISTS `{dst_dbname}`;\")\n",
    "sqlEngine.execute(f\"CREATE DATABASE `{dst_dbname}`;\")\n",
    "sqlEngine.execute(f\"USE {dst_dbname};\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8de8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_customers = \"SELECT * FROM sakila.customer;\"\n",
    "df_customers = get_sql_dataframe(sql_conn_str, src_dbname, sql_customers)\n",
    "df_customers.drop(['address_id', 'last_update'], axis=1, inplace=True)\n",
    "df_customers.rename(columns={\"customer_id\":\"customer_key\", \"store_id\":\"store_key\"}, inplace=True)\n",
    "df_customers.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d74be2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_staff = \"SELECT * FROM sakila.staff;\"\n",
    "df_staff = get_sql_dataframe(sql_conn_str, src_dbname, sql_staff)\n",
    "df_staff.drop(['address_id', 'last_update'], axis=1, inplace=True)\n",
    "df_staff.rename(columns={\"staff_id\":\"staff_key\", \"store_id\":\"store_key\"}, inplace=True)\n",
    "df_staff.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eab163",
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_stores = \"SELECT * FROM sakila.stores;\"\n",
    "df_stores = get_sql_dataframe(sql_conn_str, src_dbname, sql_stores)\n",
    "df_stores.drop(['address_id', 'last_update'], axis=1, inplace=True)\n",
    "df_stores.rename(columns={\"store_id\":\"store_key\", \"manager_staff_id\":\"manager_staff_key\"}, inplace=True)\n",
    "df_stores.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022a4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_operation = \"insert\"\n",
    "tables = [('dim_customers', df_customers, 'customer_key'),\n",
    "          ('dim_staff', df_staff, 'staff_key'),\n",
    "          ('dim_stores', df_stores, 'store_key'),\n",
    "          ('dim_date', df_date, 'date_key')]\n",
    "for table_name, dataframe, primary_key in tables:\n",
    "    set_dataframe(sql_conn_str, dst_dbname, dataframe, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd44621d",
   "metadata": {},
   "source": [
    "### MongoDB\n",
    "\n",
    "#### Export dataframes into JSON and populate MongoDB with source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b18e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export from mysql into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9772c78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = pymongo.MongoClient(conn_str[\"local\"])\n",
    "db = client[src_dbname]\n",
    "\n",
    "# Gets the path of the Current Working Directory for this Notebook, and then Appends the 'data' directory.\n",
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "\n",
    "json_files = {\"films\" : 'sakila_films.json',\n",
    "              \"languages\" : 'sakila_languages'\n",
    "              \"rentals\" : 'sakila_rentals.json',\n",
    "              \"inventory\" : 'sakila_inventory.json',\n",
    "              \"payments\" : 'sakila_payments.json'\n",
    "             }\n",
    "\n",
    "for file in json_files:\n",
    "    db.drop_collection(file)\n",
    "    json_file = os.path.join(data_dir, json_files[file])\n",
    "    with open(json_file, 'r') as openfile:\n",
    "        json_object = json.load(openfile)\n",
    "        file = db[file]\n",
    "        result = file.insert_many(json_object)\n",
    "        #print(f\"{file} was successfully loaded.\")\n",
    "\n",
    "        \n",
    "client.close()        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41747a78",
   "metadata": {},
   "source": [
    "#### ETL film dimension table into destination database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d79acc8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>film_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>release_year</th>\n",
       "      <th>rental_duration</th>\n",
       "      <th>rental_rate</th>\n",
       "      <th>length</th>\n",
       "      <th>replacement_cost</th>\n",
       "      <th>rating</th>\n",
       "      <th>special_features</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ACADEMY DINOSAUR</td>\n",
       "      <td>A Epic Drama of a Feminist And a Mad Scientist...</td>\n",
       "      <td>2006</td>\n",
       "      <td>6</td>\n",
       "      <td>0.99</td>\n",
       "      <td>86</td>\n",
       "      <td>20.99</td>\n",
       "      <td>PG</td>\n",
       "      <td>Deleted Scenes,Behind the Scenes</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ACE GOLDFINGER</td>\n",
       "      <td>A Astounding Epistle of a Database Administrat...</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>4.99</td>\n",
       "      <td>48</td>\n",
       "      <td>12.99</td>\n",
       "      <td>G</td>\n",
       "      <td>Trailers,Deleted Scenes</td>\n",
       "      <td>English</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   film_id             title  \\\n",
       "0        1  ACADEMY DINOSAUR   \n",
       "1        2    ACE GOLDFINGER   \n",
       "\n",
       "                                         description  release_year  \\\n",
       "0  A Epic Drama of a Feminist And a Mad Scientist...          2006   \n",
       "1  A Astounding Epistle of a Database Administrat...          2006   \n",
       "\n",
       "   rental_duration  rental_rate  length  replacement_cost rating  \\\n",
       "0                6         0.99      86             20.99     PG   \n",
       "1                3         4.99      48             12.99      G   \n",
       "\n",
       "                   special_features language  \n",
       "0  Deleted Scenes,Behind the Scenes  English  \n",
       "1           Trailers,Deleted Scenes  English  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {}\n",
    "collection = \"films\"\n",
    "\n",
    "df_films = get_mongo_dataframe(mongo_conn_str['local'], src_dbname, collection, query)\n",
    "df_films.drop(['last_update'], axis=1, inplace=True)\n",
    "df_films.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97b6917",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"language\"\n",
    "\n",
    "df_languages = get_mongo_dataframe(mongo_conn_str['local'], src_dbname, collection, query)\n",
    "df_languages.drop(['last_update'], axis=1, inplace=True)\n",
    "df_languages.rename(columns={\"name\":\"language\"}, inplace=True)\n",
    "df_languages.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5072762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_films = pd.merge(df_films, df_languages, on='original_language_id', how='left')\n",
    "df_films.drop(['original_language_id'], axis=1, inplace=True)\n",
    "df_films.rename(columns={\"language\":\"original_language\"}, inplace=True)\n",
    "df_films = pd.merge(df_films, df_languages, on='language_id', how='left')\n",
    "df_films.drop(['language_id'], axis=1, inplace=True)\n",
    "df_films.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca509135",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "ordered_columns = []\n",
    "df_films = df_films[ordered_columns]\n",
    "df_films.rename(columns={\"film_id\":\"film_key\"}, inplace=True)\n",
    "df_films.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65b4781",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"dim_films\"\n",
    "primary_key = \"film_key\"\n",
    "db_operation = \"insert\"\n",
    "set_dataframe(sql_conn_str, dst_dbname, df_films, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f935a1e5",
   "metadata": {},
   "source": [
    "#### ETL rental fact table into destination database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e65608",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"rentals\"\n",
    "\n",
    "df_rentals = get_mongo_dataframe(conn_str['local'], src_dbname, collection, query)\n",
    "df_rentals.rename(columns={\"customer_id\":\"renting_customer_key\", \"staff_id\":\"rental_staff_key\"}, inplace=True)\n",
    "df_rentals.drop(['last_update'], axis=1, inplace=True)\n",
    "df_rentals.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90fbb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"inventory\"\n",
    "\n",
    "df_inventory = get_mongo_dataframe(conn_str['local'], src_dbname, collection, query)\n",
    "df_inventory.drop(['last_update'], axis=1, inplace=True)\n",
    "df_inventory.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e72a59fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {}\n",
    "collection = \"payments\"\n",
    "\n",
    "df_payments = get_mongo_dataframe(conn_str['local'], src_dbname, collection, query)\n",
    "df_payments.rename(columns={\"customer_id\":\"paying_customer_key\", \"staff_id\":\"cashier_staff_key\"}, inplace=True)\n",
    "df_payments.drop(['last_update'], axis=1, inplace=True)\n",
    "df_payments.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ba331",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fact_rentals = pd.merge(df_rentals, df_inventory, on='inventory_id', how='left')\n",
    "df_fact_rentals.drop(['inventory_id'], axis=1, inplace=True)\n",
    "df_fact_rentals = pd.merge(df_rentals, df_payments, on='rental_id', how='left')\n",
    "df_fact_rentals.drop(['payment_id'], axis=1, inplace=True)\n",
    "df_fact_rentals.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb3b2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder columns\n",
    "ordered_columns = []\n",
    "df_fact_rentals = df_films[ordered_columns]\n",
    "df_fact_rentals.rename(columns={\"rental_id\":\"rental_key\"}, inplace=True)\n",
    "df_fact_rentals.insert(0, \"fact_rental_key\", range(1, df_fact_rentals.shape[0]+1))\n",
    "df_fact_rentals.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2ab38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"fact_rentals\"\n",
    "primary_key = \"fact_rental_key\"\n",
    "db_operation = \"insert\"\n",
    "set_dataframe(sql_conn_str, dst_dbname, df_fact_rentals, table_name, primary_key, db_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05435822",
   "metadata": {},
   "source": [
    "#### Check that all tables were created, populated, and inserted correctly into the destination database"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
